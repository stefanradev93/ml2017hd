{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Like v3.1 BUT no Dropout after last layer of vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gloria/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/gloria/tensorflow/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.engine import Model\n",
    "from keras.layers import Flatten, Dense, Input, Dropout\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface import utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_SIZE = 200\n",
    "BASE_DIR = '../project/all_females'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in ratings\n",
    "ratings = np.genfromtxt('./Projekt_SGE_Assessment_ErikK.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5], dtype=int8), array([197, 128,  75,  70,  50,  48]))\n"
     ]
    }
   ],
   "source": [
    "# Round (obviously imbalanced sets)\n",
    "ratings = np.round(ratings, 0).astype(np.int8)\n",
    "print(np.unique(ratings, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Distribute images across folders\n",
    "for r in np.unique(ratings).astype(np.int8):\n",
    "    if not os.path.isdir('./data/train/{}-stars'.format(r)):\n",
    "        os.makedirs('./data/train/{}-stars'.format(r))\n",
    "    if not os.path.isdir('./data/test/{}-stars'.format(r)):\n",
    "        os.makedirs('./data/test/{}-stars'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test-split:\n",
      "X_train:  (6,)\n",
      "X_test:  (6,)\n",
      "y_train:  (6,)\n",
      "y_test:  (6,)\n"
     ]
    }
   ],
   "source": [
    "### Move all images according to ratings\n",
    "images = sorted(os.listdir(BASE_DIR))\n",
    "\n",
    "### Make sure lengths of ratings and images correspond \n",
    "assert len(ratings) == len(images)\n",
    "\n",
    "### Sort images according to ratings\n",
    "ratings = ratings.tolist()\n",
    "ratings, images = zip(*sorted(zip(ratings,images)))\n",
    "ratings = np.asarray(ratings)\n",
    "\n",
    "### Count number of ratings for each category, generate train test split for each category\n",
    "unique, counts = np.unique(ratings, return_counts=True)\n",
    "\n",
    "stars = [[] for i in counts]\n",
    "stared_img = [[] for i in counts]\n",
    "accum = np.cumsum(counts)\n",
    "stars[0] = ratings[:accum[0]]\n",
    "stared_img[0] = images[:accum[0]]\n",
    "\n",
    "for i in range(1,len(counts)):\n",
    "    stars[i] = ratings[accum[i-1]:accum[i]]\n",
    "    stared_img[i] = images[accum[i-1]:accum[i]]\n",
    "\n",
    "stars = np.asarray(stars)\n",
    "stared_img = np.asarray(stared_img)\n",
    "\n",
    "assert(stars.shape == stared_img.shape)\n",
    "\n",
    "X_train = [[] for i in counts]\n",
    "X_test = [[] for i in counts]\n",
    "y_train = [[] for i in counts]\n",
    "y_test = [[] for i in counts]\n",
    "\n",
    "for i in range(len(counts)):\n",
    "    X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(stared_img[i], stars[i], test_size=0.2)\n",
    "    \n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "        \n",
    "print(\"Train-test-split:\")\n",
    "print(\"X_train: \",X_train.shape)\n",
    "print(\"X_test: \",X_test.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"y_test: \",y_test.shape)\n",
    "\n",
    "#check that all subsets of the split have the same rating\n",
    "for i in range(len(counts)):\n",
    "    assert(np.sum(y_train[i]) == i*len(y_train[i]))\n",
    "    assert(np.sum(y_test[i]) == i*len(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Loop throgh all images and store them in the dedicated folders\n",
    "#for i, r in enumerate(ratings.astype(np.int8)):\n",
    "#    src = os.path.join(BASE_DIR, images[i])\n",
    "#    dest = os.path.join('./classification/{}-stars'.format(r), images[i])\n",
    "#    shutil.copy(src, dest)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    for j in range(len(X_train[i])):\n",
    "        src = os.path.join(BASE_DIR, X_train[i][j])\n",
    "        dest = os.path.join('./data/train/{}-stars'.format(y_train[i][j]), X_train[i][j])\n",
    "        shutil.copy(src, dest)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_test[i])):\n",
    "        src = os.path.join(BASE_DIR, X_test[i][j])\n",
    "        dest = os.path.join('./data/test/{}-stars'.format(y_test[i][j]), X_test[i][j])\n",
    "        shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to use data augmentation with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, \n",
    "                             rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest',\n",
    "                             preprocessing_function=utils.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 563 images belonging to 6 classes.\n",
      "Found 275 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    './data/train/',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    './data/test/',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers\n",
    "vgg_base = VGGFace(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling='max')\n",
    "last_layer = vgg_base.get_layer('global_max_pooling2d_1').output\n",
    "#X = Dropout(0.2)(last_layer)\n",
    "X = Dense(256, activation='relu', name='fc6')(last_layer)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(128, activation='relu', name='fc7')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "output = Dense(len(np.unique(ratings)), activation='softmax')(X)\n",
    "model = Model(inputs=vgg_base.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze vgg layers\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute class weights since we have unbalaned classes\n",
    "class_weight = class_weight.compute_class_weight('balanced', \n",
    "                                                 np.unique(ratings), \n",
    "                                                 ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(clipnorm=1.0),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./weights-v3.2.hdf5', verbose=1, save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 79s 790ms/step - loss: 1.5670 - acc: 0.3610 - val_loss: 1.4097 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.40973, saving model to ./weights-v3.2.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=1,\n",
    "    class_weight=class_weight,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4328 - acc: 0.4152 - val_loss: 1.3664 - val_acc: 0.4618\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.40973 to 1.36643, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4290 - acc: 0.4106 - val_loss: 1.3538 - val_acc: 0.4873\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.36643 to 1.35377, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4006 - acc: 0.4219 - val_loss: 1.3383 - val_acc: 0.4582\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.35377 to 1.33826, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4163 - acc: 0.4287 - val_loss: 1.3318 - val_acc: 0.4764\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.33826 to 1.33182, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3606 - acc: 0.4735 - val_loss: 1.3200 - val_acc: 0.4982\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.33182 to 1.31999, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3767 - acc: 0.4488 - val_loss: 1.3302 - val_acc: 0.4836\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3747 - acc: 0.4284 - val_loss: 1.3233 - val_acc: 0.4582\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3708 - acc: 0.4509 - val_loss: 1.3178 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.31999 to 1.31777, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3673 - acc: 0.4416 - val_loss: 1.3065 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.31777 to 1.30653, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3514 - acc: 0.4586 - val_loss: 1.2923 - val_acc: 0.5455\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.30653 to 1.29229, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4018 - acc: 0.4353 - val_loss: 1.2818 - val_acc: 0.5091\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.29229 to 1.28180, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3406 - acc: 0.4710 - val_loss: 1.2576 - val_acc: 0.4909\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.28180 to 1.25762, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2957 - acc: 0.4867 - val_loss: 1.2465 - val_acc: 0.5091\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.25762 to 1.24646, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3131 - acc: 0.4829 - val_loss: 1.2474 - val_acc: 0.5455\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3274 - acc: 0.4844 - val_loss: 1.2279 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.24646 to 1.22792, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2769 - acc: 0.4957 - val_loss: 1.2348 - val_acc: 0.5091\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2878 - acc: 0.5089 - val_loss: 1.2692 - val_acc: 0.5309\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2711 - acc: 0.5123 - val_loss: 1.2088 - val_acc: 0.5018\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.22792 to 1.20885, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2354 - acc: 0.5355 - val_loss: 1.2180 - val_acc: 0.5091\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3133 - acc: 0.5014 - val_loss: 1.2179 - val_acc: 0.5382\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2465 - acc: 0.4866 - val_loss: 1.2137 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2721 - acc: 0.4919 - val_loss: 1.1760 - val_acc: 0.4982\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.20885 to 1.17597, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2066 - acc: 0.5365 - val_loss: 1.2137 - val_acc: 0.5273\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2569 - acc: 0.5156 - val_loss: 1.1707 - val_acc: 0.5745\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.17597 to 1.17071, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2580 - acc: 0.5225 - val_loss: 1.1506 - val_acc: 0.5709\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.17071 to 1.15059, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2086 - acc: 0.5081 - val_loss: 1.1777 - val_acc: 0.5782\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2231 - acc: 0.5255 - val_loss: 1.1333 - val_acc: 0.5273\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.15059 to 1.13326, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1991 - acc: 0.5367 - val_loss: 1.1469 - val_acc: 0.5491\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2263 - acc: 0.5156 - val_loss: 1.1865 - val_acc: 0.5164\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1145 - acc: 0.5797 - val_loss: 1.1607 - val_acc: 0.5527\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2284 - acc: 0.5134 - val_loss: 1.1371 - val_acc: 0.5418\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2168 - acc: 0.5086 - val_loss: 1.1272 - val_acc: 0.5855\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.13326 to 1.12723, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1208 - acc: 0.5671 - val_loss: 1.0969 - val_acc: 0.5782\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.12723 to 1.09690, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1070 - acc: 0.5759 - val_loss: 1.1296 - val_acc: 0.5455\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1042 - acc: 0.5695 - val_loss: 1.0711 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.09690 to 1.07111, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1873 - acc: 0.5580 - val_loss: 1.1001 - val_acc: 0.5673\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0866 - acc: 0.5977 - val_loss: 1.0524 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.07111 to 1.05242, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1229 - acc: 0.5524 - val_loss: 1.0041 - val_acc: 0.5745\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.05242 to 1.00411, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1380 - acc: 0.5513 - val_loss: 1.0780 - val_acc: 0.5818\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1403 - acc: 0.5708 - val_loss: 1.0708 - val_acc: 0.5745\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0667 - acc: 0.5870 - val_loss: 1.0141 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1070 - acc: 0.5790 - val_loss: 1.0303 - val_acc: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0429 - acc: 0.5893 - val_loss: 1.0072 - val_acc: 0.6182\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0522 - acc: 0.5867 - val_loss: 1.0141 - val_acc: 0.6291\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0529 - acc: 0.5960 - val_loss: 1.0223 - val_acc: 0.6145\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0483 - acc: 0.6339 - val_loss: 1.0184 - val_acc: 0.6255\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0080 - acc: 0.6512 - val_loss: 0.9465 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.00411 to 0.94649, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0389 - acc: 0.5807 - val_loss: 0.9960 - val_acc: 0.6182\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0029 - acc: 0.6339 - val_loss: 1.0249 - val_acc: 0.5927\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0350 - acc: 0.6004 - val_loss: 0.9430 - val_acc: 0.6327\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.94649 to 0.94300, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0576 - acc: 0.5848 - val_loss: 0.9391 - val_acc: 0.6873\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.94300 to 0.93910, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.9490 - acc: 0.6355 - val_loss: 0.9068 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.93910 to 0.90681, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0287 - acc: 0.6094 - val_loss: 0.9528 - val_acc: 0.6255\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0260 - acc: 0.6069 - val_loss: 0.9825 - val_acc: 0.6327\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.9497 - acc: 0.6527 - val_loss: 0.9309 - val_acc: 0.6436\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.9559 - acc: 0.6116 - val_loss: 0.9335 - val_acc: 0.6727\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.9877 - acc: 0.6529 - val_loss: 0.9000 - val_acc: 0.7018\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.90681 to 0.90003, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0058 - acc: 0.6295 - val_loss: 0.9461 - val_acc: 0.6582\n",
      "\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.9577 - acc: 0.6326 - val_loss: 0.8502 - val_acc: 0.7091\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.90003 to 0.85019, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.9446 - acc: 0.6771 - val_loss: 0.8807 - val_acc: 0.6618\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.9651 - acc: 0.6228 - val_loss: 0.8563 - val_acc: 0.6727\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.9160 - acc: 0.6607 - val_loss: 0.8583 - val_acc: 0.6873\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.9069 - acc: 0.6667 - val_loss: 0.8223 - val_acc: 0.6873\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.85019 to 0.82232, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.9363 - acc: 0.6348 - val_loss: 0.8599 - val_acc: 0.7055\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8823 - acc: 0.6808 - val_loss: 0.8127 - val_acc: 0.7055\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.82232 to 0.81274, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8999 - acc: 0.6706 - val_loss: 0.8170 - val_acc: 0.6909\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.9314 - acc: 0.6749 - val_loss: 0.8169 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8426 - acc: 0.6863 - val_loss: 0.7685 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.81274 to 0.76851, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8738 - acc: 0.6721 - val_loss: 0.8766 - val_acc: 0.6836\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7887 - acc: 0.6965 - val_loss: 0.7850 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8603 - acc: 0.6830 - val_loss: 0.7693 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8606 - acc: 0.6891 - val_loss: 0.8070 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8300 - acc: 0.6955 - val_loss: 0.7257 - val_acc: 0.7927\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.76851 to 0.72567, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8452 - acc: 0.6923 - val_loss: 0.7932 - val_acc: 0.7091\n",
      "\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8175 - acc: 0.7025 - val_loss: 0.7939 - val_acc: 0.6945\n",
      "\n",
      "Epoch 00075: val_loss did not improve\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8646 - acc: 0.6652 - val_loss: 0.8418 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7993 - acc: 0.7155 - val_loss: 0.7613 - val_acc: 0.7309\n",
      "\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8445 - acc: 0.6830 - val_loss: 0.7257 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.8447 - acc: 0.6634 - val_loss: 0.7373 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7501 - acc: 0.7299 - val_loss: 0.7332 - val_acc: 0.7382\n",
      "\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7647 - acc: 0.7476 - val_loss: 0.6849 - val_acc: 0.7564\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.72567 to 0.68492, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7756 - acc: 0.7369 - val_loss: 0.6730 - val_acc: 0.7818\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.68492 to 0.67298, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7745 - acc: 0.7344 - val_loss: 0.6645 - val_acc: 0.7782\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.67298 to 0.66451, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7065 - acc: 0.7292 - val_loss: 0.6544 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.66451 to 0.65439, saving model to ./weights-v3.2.hdf5\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7021 - acc: 0.7722 - val_loss: 0.6926 - val_acc: 0.7564\n",
      "\n",
      "Epoch 00085: val_loss did not improve\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7000 - acc: 0.7476 - val_loss: 0.5677 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.65439 to 0.56766, saving model to ./weights-v3.2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7448 - acc: 0.7135 - val_loss: 0.6624 - val_acc: 0.7636\n",
      "\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6764 - acc: 0.7522 - val_loss: 0.7071 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00088: val_loss did not improve\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7283 - acc: 0.7386 - val_loss: 0.6677 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6922 - acc: 0.7610 - val_loss: 0.6231 - val_acc: 0.7818\n",
      "\n",
      "Epoch 00090: val_loss did not improve\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6746 - acc: 0.7755 - val_loss: 0.6050 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6849 - acc: 0.7583 - val_loss: 0.6927 - val_acc: 0.7455\n",
      "\n",
      "Epoch 00092: val_loss did not improve\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6953 - acc: 0.7500 - val_loss: 0.6254 - val_acc: 0.7855\n",
      "\n",
      "Epoch 00093: val_loss did not improve\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7024 - acc: 0.7695 - val_loss: 0.5951 - val_acc: 0.7927\n",
      "\n",
      "Epoch 00094: val_loss did not improve\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6931 - acc: 0.7234 - val_loss: 0.6671 - val_acc: 0.7855\n",
      "\n",
      "Epoch 00095: val_loss did not improve\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6608 - acc: 0.7772 - val_loss: 0.6459 - val_acc: 0.7745\n",
      "\n",
      "Epoch 00096: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=453//64,\n",
    "    epochs=500,\n",
    "    class_weight=class_weight,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[earlystop, checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./models/love_classifierv3.2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose candidates from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 0 1 0 4 1 3 1 1 0 4 1 0 1 1 1 1 4 1 3 1 2 2 4 1 2 2 2 2\n",
      " 2 2 2 2 4 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 4 4 4 4 4 4 4 4 5 5 5 5 5 3\n",
      " 5 5 5 5]\n",
      "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      " array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5])]\n"
     ]
    }
   ],
   "source": [
    "#freeze layers\n",
    "#for layer in model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "#transform X_test & y_test so all data is in one dimension \n",
    "realNumDim = 0\n",
    "for i in range(X_test.shape[0]):\n",
    "    for j in range(len(X_test[i])):\n",
    "        realNumDim += 1\n",
    "    \n",
    "#get test data (unmodified)\n",
    "data_test = np.zeros((realNumDim, IMG_SIZE, IMG_SIZE, 3))    \n",
    "last_set = 0\n",
    "for i in range(X_test.shape[0]): #iterate over #stars\n",
    "    for idx, _im in enumerate(X_test[i]): #iterate over images\n",
    "        _img = image.load_img(os.path.join(BASE_DIR, _im), target_size=(IMG_SIZE,IMG_SIZE))\n",
    "        _x = image.img_to_array(_img)\n",
    "        _x = np.expand_dims(_x, axis=0)\n",
    "        data_test[last_set, :, :, :] = utils.preprocess_input(_x, version=1) / .255\n",
    "        last_set += 1\n",
    "\n",
    "predictions = model.predict(data_test)\n",
    "pred_classes = predictions.argmax(axis=-1)\n",
    "\n",
    "print(pred_classes)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
