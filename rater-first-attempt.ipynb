{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import  Model\n",
    "from keras.layers import Flatten, Dense, Input, Dropout\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface import utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_base = VGGFace(include_top=False, input_shape=(224, 224, 3), pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers\n",
    "last_layer = vgg_base.get_layer('global_max_pooling2d_1').output\n",
    "X = Dropout(0.2)(last_layer)\n",
    "# x = Flatten(name='flatten')(last_layer)\n",
    "X = Dense(256, activation='relu', name='fc6')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(128, activation='relu', name='fc7')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "output = Dense(1, activation='linear')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=vgg_base.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'fc6/kernel:0' shape=(512, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'fc6/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'fc7/kernel:0' shape=(256, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'fc7/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(128, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure weights are not trainable\n",
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(clipnorm=1.0),loss='mean_absolute_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 14,879,041\n",
      "Trainable params: 164,353\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'C:\\\\Users\\\\Lenovo 500\\\\Desktop\\\\Projects\\\\LoveClassifier\\\\all_females'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT !\n",
    "# LISTDIR returns the files as indexed by the filessystem\n",
    "# not necessarily in alphanumeric order, so need to sort them!\n",
    "N_IMAGES = len(os.listdir(BASE_DIR))\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "X_train = np.zeros((N_IMAGES, IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "y_train = np.zeros(N_IMAGES)\n",
    "\n",
    "for idx, _im in enumerate(sorted(os.listdir(BASE_DIR))):\n",
    "    # Change the image path with yours.\n",
    "    _img = image.load_img(os.path.join(BASE_DIR, _im), target_size=IMAGE_SIZE)\n",
    "    _x = image.img_to_array(_img)\n",
    "    _x = np.expand_dims(_x, axis=0)\n",
    "    X_train[idx, :, :, :] = utils.preprocess_input(_x, version=1) / .255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure images are ok\n",
    "assert ~np.any(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load ratings\n",
    "ratings = np.genfromtxt('./Projekt_SGE_Assessment_ErikK.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize ratings\n",
    "ratings_z = (ratings - np.mean(ratings)) / np.std(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 454 samples, validate on 114 samples\n",
      "Epoch 1/5\n",
      "454/454 [==============================] - 607s - loss: 175.7659 - mean_absolute_error: 175.7659 - val_loss: 85.0006 - val_mean_absolute_error: 85.0006\n",
      "Epoch 2/5\n",
      "454/454 [==============================] - 597s - loss: 66.0431 - mean_absolute_error: 66.0431 - val_loss: 32.8149 - val_mean_absolute_error: 32.8149\n",
      "Epoch 3/5\n",
      "454/454 [==============================] - 596s - loss: 44.7694 - mean_absolute_error: 44.7694 - val_loss: 9.8013 - val_mean_absolute_error: 9.8013\n",
      "Epoch 4/5\n",
      "454/454 [==============================] - 578s - loss: 27.8944 - mean_absolute_error: 27.8944 - val_loss: 8.3531 - val_mean_absolute_error: 8.3531\n",
      "Epoch 5/5\n",
      "454/454 [==============================] - 568s - loss: 19.2702 - mean_absolute_error: 19.2702 - val_loss: 4.4954 - val_mean_absolute_error: 4.4954\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, ratings, batch_size=64, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 454 samples, validate on 114 samples\n",
      "Epoch 1/5\n",
      "454/454 [==============================] - 593s - loss: 16.2091 - mean_absolute_error: 16.2091 - val_loss: 7.0996 - val_mean_absolute_error: 7.0996\n",
      "Epoch 2/5\n",
      "454/454 [==============================] - 664s - loss: 11.2102 - mean_absolute_error: 11.2102 - val_loss: 3.3607 - val_mean_absolute_error: 3.3607\n",
      "Epoch 3/5\n",
      "454/454 [==============================] - 553s - loss: 8.1728 - mean_absolute_error: 8.1728 - val_loss: 2.5899 - val_mean_absolute_error: 2.5899\n",
      "Epoch 4/5\n",
      "454/454 [==============================] - 539s - loss: 4.4586 - mean_absolute_error: 4.4586 - val_loss: 1.3857 - val_mean_absolute_error: 1.3857\n",
      "Epoch 5/5\n",
      "454/454 [==============================] - 548s - loss: 3.8061 - mean_absolute_error: 3.8061 - val_loss: 1.3797 - val_mean_absolute_error: 1.3797\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_train, ratings, batch_size=64, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('love_classifierv0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
