{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import  Model\n",
    "from keras.layers import Flatten, Dense, Input, Dropout, Activation\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface import utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_SIZE = 200\n",
    "IMG_DIR = '../project/all_females'\n",
    "RATING_PATH = './Projekt_SGE_Assessment_ErikK.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable weights:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 200, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 200, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 100, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc12 (Dense)                 (None, 8)                 4104      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 14,981,457\n",
      "Trainable params: 266,769\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "#create function for calling clipped ReLU\n",
    "def create_relu_advanced(max_value=1.):        \n",
    "    def relu_advanced(x):\n",
    "        return K.relu(x, max_value=K.cast_to_floatx(max_value))\n",
    "    return relu_advanced\n",
    "\n",
    "vgg_base = VGGFace(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling='max')\n",
    "\n",
    "# Add custom layers\n",
    "last_layer = vgg_base.get_layer('global_max_pooling2d_1').output\n",
    "X = Dropout(0.2)(last_layer)\n",
    "# x = Flatten(name='flatten')(last_layer)\n",
    "X = Dense(512, activation='relu', name='fc6')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "#X = Dense(256, activation='relu', name='fc7')(X)\n",
    "#X = Dropout(0.2)(X)\n",
    "#X = Dense(128, activation='relu', name='fc8')(X)\n",
    "#X = Dropout(0.2)(X)\n",
    "#X = Dense(64, activation='relu', name='fc9')(X)\n",
    "#X = Dropout(0.2)(X)\n",
    "#X = Dense(32, activation='relu', name='fc10')(X)\n",
    "#X = Dropout(0.2)(X)\n",
    "#X = Dense(16, activation='relu', name='fc11')(X)\n",
    "#X = Dropout(0.2)(X)\n",
    "X = Dense(8, activation='relu', name='fc12')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "output = Dense(1, activation=create_relu_advanced(max_value=5))(X)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=vgg_base.input, outputs=output)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Make sure weights are not trainable\n",
    "print(\"Trainable weights:\")\n",
    "model.trainable_weights\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001,clipnorm=1.0),loss='mean_absolute_error', metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "### **Please remember to delete the train & test folders if you have run this cell before!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test-split:\n",
      "X_train:  (454,)\n",
      "X_test:  (114,)\n",
      "y_train:  (454,)\n",
      "y_test:  (114,)\n"
     ]
    }
   ],
   "source": [
    "# Read in ratings\n",
    "ratings = np.genfromtxt(RATING_PATH)\n",
    "\n",
    "### Distribute images across folders\n",
    "if not os.path.isdir('./data/train/train'):\n",
    "    os.makedirs('./data/train/train')\n",
    "if not os.path.isdir('./data/test/test'):\n",
    "    os.makedirs('./data/test/test')\n",
    "        \n",
    "### Move all images according to ratings\n",
    "images = sorted(os.listdir(IMG_DIR))\n",
    "\n",
    "### Make sure lengths of ratings and images correspond \n",
    "assert len(ratings) == len(images)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, ratings, test_size=0.2)\n",
    "    \n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "        \n",
    "print(\"Train-test-split:\")\n",
    "print(\"X_train: \",X_train.shape)\n",
    "print(\"X_test: \",X_test.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"y_test: \",y_test.shape)\n",
    "\n",
    "data_train = np.zeros((X_train.shape[0], IMG_SIZE, IMG_SIZE, 3))\n",
    "data_test = np.zeros((X_test.shape[0], IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "for idx, _im in enumerate(X_train):\n",
    "    # Change the image path with yours.\n",
    "    _img = image.load_img(os.path.join(IMG_DIR, _im), target_size=(IMG_SIZE,IMG_SIZE))\n",
    "    _x = image.img_to_array(_img)\n",
    "    _x = np.expand_dims(_x, axis=0)\n",
    "    data_train[idx, :, :, :] = utils.preprocess_input(_x, version=1) / .255 \n",
    "    \n",
    "# Same for test data\n",
    "for idx, _im in enumerate(X_test):   \n",
    "    _img = image.load_img(os.path.join(IMG_DIR, _im), target_size=(IMG_SIZE,IMG_SIZE))\n",
    "    _x = image.img_to_array(_img)\n",
    "    _x = np.expand_dims(_x, axis=0)\n",
    "    data_test[idx, :, :, :] = utils.preprocess_input(_x, version=1) / .255\n",
    "\n",
    "### Loop throgh all images and store them in the dedicated folders\n",
    "#for img in X_train:\n",
    "#    src = os.path.join(IMG_DIR, img)\n",
    "#    dest = os.path.join('./data/train/train', img)\n",
    "#    shutil.copy(src, dest)\n",
    "\n",
    "#for img in X_test:\n",
    "#    src = os.path.join(IMG_DIR, img)\n",
    "#    dest = os.path.join('./data/test/test', img)\n",
    "#    shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, \n",
    "                             rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest',\n",
    "                             preprocessing_function=utils.preprocess_input)\n",
    "\n",
    "datagen.fit(data_train)\n",
    "\n",
    "#train_generator = datagen.flow_from_directory(\n",
    "#    './data/train',\n",
    "#    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "#    batch_size=64,\n",
    "#    class_mode=None\n",
    "#)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen.fit(data_test)\n",
    "\n",
    "#test_generator = test_datagen.flow_from_directory(\n",
    "#    './data/test',\n",
    "#    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "#    batch_size=64,\n",
    "#    class_mode=None\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 1.3578 - mean_absolute_error: 1.3578 - val_loss: 1.1619 - val_mean_absolute_error: 1.1619\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.16192, saving model to ./weights-v4.2.hdf5\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./weights-v4.2.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(data_train, y_train, batch_size=64),\n",
    "    steps_per_epoch=100,\n",
    "    epochs=1,\n",
    "    validation_data=test_datagen.flow(data_test, y_test, batch_size=64),\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 6s 895ms/step - loss: 1.2732 - mean_absolute_error: 1.2732 - val_loss: 1.1641 - val_mean_absolute_error: 1.1641\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 5s 731ms/step - loss: 1.3331 - mean_absolute_error: 1.3331 - val_loss: 1.1681 - val_mean_absolute_error: 1.1681\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 6s 842ms/step - loss: 1.3101 - mean_absolute_error: 1.3101 - val_loss: 1.1638 - val_mean_absolute_error: 1.1638\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 5s 708ms/step - loss: 1.2892 - mean_absolute_error: 1.2892 - val_loss: 1.1643 - val_mean_absolute_error: 1.1643\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 6s 828ms/step - loss: 1.2414 - mean_absolute_error: 1.2414 - val_loss: 1.1519 - val_mean_absolute_error: 1.1519\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16192 to 1.15190, saving model to ./weights-v4.2.hdf5\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 6s 804ms/step - loss: 1.4036 - mean_absolute_error: 1.4036 - val_loss: 1.1379 - val_mean_absolute_error: 1.1379\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.15190 to 1.13792, saving model to ./weights-v4.2.hdf5\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 5s 765ms/step - loss: 1.2145 - mean_absolute_error: 1.2145 - val_loss: 1.1388 - val_mean_absolute_error: 1.1388\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 5s 764ms/step - loss: 1.2879 - mean_absolute_error: 1.2879 - val_loss: 1.1589 - val_mean_absolute_error: 1.1589\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 5s 746ms/step - loss: 1.3291 - mean_absolute_error: 1.3291 - val_loss: 1.1367 - val_mean_absolute_error: 1.1367\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.13792 to 1.13675, saving model to ./weights-v4.2.hdf5\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 5s 745ms/step - loss: 1.2819 - mean_absolute_error: 1.2819 - val_loss: 1.1222 - val_mean_absolute_error: 1.1222\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.13675 to 1.12220, saving model to ./weights-v4.2.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    datagen.flow(data_train, y_train, batch_size=64),\n",
    "    steps_per_epoch=453//64,\n",
    "    epochs=10,\n",
    "    validation_data=test_datagen.flow(data_test, y_test, batch_size=64),\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./models/love_classifierv4.2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Choose candidates from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      "[0.  1.  1.  0.  0.  2.  5.  1.  5.  0.  4.  0.  0.  1.  3.  0.  0.  1.\n",
      " 1.  0.  1.  0.  2.  0.  3.  0.  4.  1.  0.  0.  0.  0.  0.  2.  0.  1.\n",
      " 5.  2.  0.  0.  5.  5.  2.  2.  0.  0.  1.  0.  2.  0.  0.  3.  1.  0.\n",
      " 1.  0.  2.  3.  0.  0.  2.  0.  0.  0.  0.  1.  1.  2.  2.  4.  0.  3.\n",
      " 0.  0.  3.  1.  1.  4.  1.  0.  1.  4.  4.5 0.  1.  0.  1.  0.  0.  4.\n",
      " 4.  0.  3.  4.  5.  1.  1.  3.5 0.  1.  0.  3.  2.  4.  5.  0.  0.  5.\n",
      " 1.  1.  1.  1.  5.  0. ]\n"
     ]
    }
   ],
   "source": [
    "#freeze layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "candidates = data_test\n",
    "candidates = np.expand_dims(candidates, axis=0)\n",
    "predictions = np.zeros(candidates.shape[1])\n",
    "\n",
    "for i in range(candidates.shape[1]):\n",
    "    predictions[i] = model.predict(candidates[:,i])\n",
    "\n",
    "#sort predictions\n",
    "predictions = predictions[np.argsort(predictions)]\n",
    "print(predictions)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^ Network should make more differentiated predictions. Like 3.36633825.\n",
    "See v4.2 for continuation of this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
