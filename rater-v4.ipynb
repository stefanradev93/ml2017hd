{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gloria/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/gloria/tensorflow/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.engine import  Model\n",
    "from keras.layers import Flatten, Dense, Input, Dropout\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface import utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_SIZE = 200\n",
    "IMG_DIR = '../project/all_females'\n",
    "RATING_PATH = './Projekt_SGE_Assessment_ErikK.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable weights:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 200, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 200, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 100, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 14,879,041\n",
      "Trainable params: 164,353\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "vgg_base = VGGFace(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling='max')\n",
    "\n",
    "# Add custom layers\n",
    "last_layer = vgg_base.get_layer('global_max_pooling2d_1').output\n",
    "#X = Dropout(0.2)(last_layer)\n",
    "# x = Flatten(name='flatten')(last_layer)\n",
    "X = Dense(256, activation='relu', name='fc6')(last_layer)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(128, activation='relu', name='fc7')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "output = Dense(1, activation='linear')(X)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=vgg_base.input, outputs=output)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Make sure weights are not trainable\n",
    "print(\"Trainable weights:\")\n",
    "model.trainable_weights\n",
    "\n",
    "model.compile(optimizer=Adam(clipnorm=1.0),loss='mean_absolute_error', metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "### **Please remember to delete the train & test folders if you have run this cell before!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test-split:\n",
      "X_train:  (454,)\n",
      "X_test:  (114,)\n",
      "y_train:  (454,)\n",
      "y_test:  (114,)\n"
     ]
    }
   ],
   "source": [
    "# Read in ratings\n",
    "ratings = np.genfromtxt(RATING_PATH)\n",
    "\n",
    "### Distribute images across folders\n",
    "if not os.path.isdir('./data/train/train'):\n",
    "    os.makedirs('./data/train/train')\n",
    "if not os.path.isdir('./data/test/test'):\n",
    "    os.makedirs('./data/test/test')\n",
    "        \n",
    "### Move all images according to ratings\n",
    "images = sorted(os.listdir(IMG_DIR))\n",
    "\n",
    "### Make sure lengths of ratings and images correspond \n",
    "assert len(ratings) == len(images)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, ratings, test_size=0.2)\n",
    "    \n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "        \n",
    "print(\"Train-test-split:\")\n",
    "print(\"X_train: \",X_train.shape)\n",
    "print(\"X_test: \",X_test.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"y_test: \",y_test.shape)\n",
    "\n",
    "data_train = np.zeros((X_train.shape[0], IMG_SIZE, IMG_SIZE, 3))\n",
    "data_test = np.zeros((X_test.shape[0], IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "for idx, _im in enumerate(X_train):\n",
    "    # Change the image path with yours.\n",
    "    _img = image.load_img(os.path.join(IMG_DIR, _im), target_size=(IMG_SIZE,IMG_SIZE))\n",
    "    _x = image.img_to_array(_img)\n",
    "    _x = np.expand_dims(_x, axis=0)\n",
    "    data_train[idx, :, :, :] = utils.preprocess_input(_x, version=1) / .255 \n",
    "    \n",
    "# Same for test data\n",
    "for idx, _im in enumerate(X_test):   \n",
    "    _img = image.load_img(os.path.join(IMG_DIR, _im), target_size=(IMG_SIZE,IMG_SIZE))\n",
    "    _x = image.img_to_array(_img)\n",
    "    _x = np.expand_dims(_x, axis=0)\n",
    "    data_test[idx, :, :, :] = utils.preprocess_input(_x, version=1) / .255\n",
    "\n",
    "### Loop throgh all images and store them in the dedicated folders\n",
    "#for img in X_train:\n",
    "#    src = os.path.join(IMG_DIR, img)\n",
    "#    dest = os.path.join('./data/train/train', img)\n",
    "#    shutil.copy(src, dest)\n",
    "\n",
    "#for img in X_test:\n",
    "#    src = os.path.join(IMG_DIR, img)\n",
    "#    dest = os.path.join('./data/test/test', img)\n",
    "#    shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, \n",
    "                             rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest',\n",
    "                             preprocessing_function=utils.preprocess_input)\n",
    "\n",
    "datagen.fit(data_train)\n",
    "\n",
    "#train_generator = datagen.flow_from_directory(\n",
    "#    './data/train',\n",
    "#    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "#    batch_size=64,\n",
    "#    class_mode=None\n",
    "#)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen.fit(data_test)\n",
    "\n",
    "#test_generator = test_datagen.flow_from_directory(\n",
    "#    './data/test',\n",
    "#    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "#    batch_size=64,\n",
    "#    class_mode=None\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 75s 754ms/step - loss: 1.2488 - mean_absolute_error: 1.2488 - val_loss: 1.1024 - val_mean_absolute_error: 1.1024\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.10244, saving model to ./weights-v4.hdf5\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./weights-v4.hdf5', verbose=1, save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=10, verbose=0)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(data_train, y_train, batch_size=64),\n",
    "    steps_per_epoch=100,\n",
    "    epochs=1,\n",
    "    validation_data=test_datagen.flow(data_test, y_test, batch_size=64),\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 6s 830ms/step - loss: 1.0442 - mean_absolute_error: 1.0442 - val_loss: 1.2420 - val_mean_absolute_error: 1.2420\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 6s 789ms/step - loss: 1.1659 - mean_absolute_error: 1.1659 - val_loss: 1.1032 - val_mean_absolute_error: 1.1032\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 6s 846ms/step - loss: 1.0962 - mean_absolute_error: 1.0962 - val_loss: 1.1250 - val_mean_absolute_error: 1.1250\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 5s 774ms/step - loss: 1.0448 - mean_absolute_error: 1.0448 - val_loss: 1.0852 - val_mean_absolute_error: 1.0852\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.10244 to 1.08519, saving model to ./weights-v4.hdf5\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 5s 767ms/step - loss: 1.1789 - mean_absolute_error: 1.1789 - val_loss: 1.1913 - val_mean_absolute_error: 1.1913\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 5s 770ms/step - loss: 1.1643 - mean_absolute_error: 1.1643 - val_loss: 1.1732 - val_mean_absolute_error: 1.1732\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 5s 781ms/step - loss: 1.1213 - mean_absolute_error: 1.1213 - val_loss: 1.1951 - val_mean_absolute_error: 1.1951\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 5s 769ms/step - loss: 1.0739 - mean_absolute_error: 1.0739 - val_loss: 1.1079 - val_mean_absolute_error: 1.1079\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 5s 772ms/step - loss: 1.0475 - mean_absolute_error: 1.0475 - val_loss: 1.1683 - val_mean_absolute_error: 1.1683\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 6s 850ms/step - loss: 1.0464 - mean_absolute_error: 1.0464 - val_loss: 1.0798 - val_mean_absolute_error: 1.0798\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.08519 to 1.07976, saving model to ./weights-v4.hdf5\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 5s 737ms/step - loss: 1.0561 - mean_absolute_error: 1.0561 - val_loss: 1.1160 - val_mean_absolute_error: 1.1160\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 5s 772ms/step - loss: 1.0565 - mean_absolute_error: 1.0565 - val_loss: 1.0267 - val_mean_absolute_error: 1.0267\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.07976 to 1.02673, saving model to ./weights-v4.hdf5\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 5s 775ms/step - loss: 1.1100 - mean_absolute_error: 1.1100 - val_loss: 1.1733 - val_mean_absolute_error: 1.1733\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 6s 851ms/step - loss: 1.0246 - mean_absolute_error: 1.0246 - val_loss: 1.0520 - val_mean_absolute_error: 1.0520\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 5s 776ms/step - loss: 0.9289 - mean_absolute_error: 0.9289 - val_loss: 1.0846 - val_mean_absolute_error: 1.0846\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 5s 780ms/step - loss: 0.9719 - mean_absolute_error: 0.9719 - val_loss: 1.0858 - val_mean_absolute_error: 1.0858\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 5s 765ms/step - loss: 0.9115 - mean_absolute_error: 0.9115 - val_loss: 1.0621 - val_mean_absolute_error: 1.0621\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 5s 766ms/step - loss: 1.0082 - mean_absolute_error: 1.0082 - val_loss: 1.1547 - val_mean_absolute_error: 1.1547\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 5s 783ms/step - loss: 0.9771 - mean_absolute_error: 0.9771 - val_loss: 1.1521 - val_mean_absolute_error: 1.1521\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 5s 775ms/step - loss: 1.0416 - mean_absolute_error: 1.0416 - val_loss: 1.0657 - val_mean_absolute_error: 1.0657\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 6s 853ms/step - loss: 0.9471 - mean_absolute_error: 0.9471 - val_loss: 1.0504 - val_mean_absolute_error: 1.0504\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 5s 689ms/step - loss: 0.9505 - mean_absolute_error: 0.9505 - val_loss: 1.0623 - val_mean_absolute_error: 1.0623\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    datagen.flow(data_train, y_train, batch_size=64),\n",
    "    steps_per_epoch=453//64,\n",
    "    epochs=500,\n",
    "    validation_data=test_datagen.flow(data_test, y_test, batch_size=64),\n",
    "    callbacks=[earlystop, checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./models/love_classifierv4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Choose candidates from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -44.57193756   24.91769218   34.64692688   44.47531128   45.82447052\n",
      "   48.15081406   54.00756454   61.11362839   62.72498322   70.58784485\n",
      "   71.54866791   85.23001099   88.61009979   93.2234726    93.48945618\n",
      "   98.20302582   98.89201355  112.62640381  113.94422913  114.61132812\n",
      "  120.41316986  126.86641693  129.6708374   138.25990295  139.81570435\n",
      "  147.0196991   149.84315491  154.3290863   160.19422913  163.05923462\n",
      "  172.86106873  175.10250854  176.3145752   177.30130005  183.09207153\n",
      "  189.90960693  192.25389099  193.46359253  193.55125427  199.19624329\n",
      "  209.00604248  211.37651062  215.48513794  224.53437805  231.57740784\n",
      "  234.38848877  235.08442688  244.204422    252.26107788  253.86560059\n",
      "  259.87078857  260.29437256  292.98849487  299.96310425  301.06692505\n",
      "  301.48361206  304.7258606   311.63815308  313.17712402  315.8324585\n",
      "  317.42904663  327.69815063  327.99502563  337.35571289  359.45306396\n",
      "  359.68722534  365.92700195  378.36444092  384.04888916  385.38565063\n",
      "  391.81750488  392.25848389  400.40328979  406.44412231  417.253479\n",
      "  442.94216919  452.27624512  456.41433716  483.27114868  518.03820801\n",
      "  524.24108887  529.05310059  549.08441162  550.81628418  550.95013428\n",
      "  569.94641113  584.7355957   590.72906494  617.70794678  624.78869629\n",
      "  626.76330566  645.93353271  648.80206299  669.50262451  675.65740967\n",
      "  682.50976562  686.92059326  707.1973877   711.10528564  728.10223389\n",
      "  730.67266846  772.53326416  775.23028564  832.34729004  838.09667969\n",
      "  855.26531982  898.11627197  901.95837402  942.87286377  957.8840332\n",
      " 1020.21899414 1021.1539917  1034.05871582 1273.09191895]\n"
     ]
    }
   ],
   "source": [
    "#freeze layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "candidates = data_test\n",
    "candidates = np.expand_dims(candidates, axis=0)\n",
    "predictions = np.zeros(candidates.shape[1])\n",
    "\n",
    "for i in range(candidates.shape[1]):\n",
    "    predictions[i] = model.predict(candidates[:,i])\n",
    "\n",
    "#sort predictions\n",
    "predictions = predictions[np.argsort(predictions)]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^ Output for regression should be between 0 & 5. Need to change activation of last layer, see v4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
